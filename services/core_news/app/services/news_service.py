import logging
import httpx
import uuid
import os
from datetime import datetime, timezone, timedelta
from typing import Optional, List
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession
import sqlalchemy as sa
import datetime as dt

from common.models.markethistory import NewsSentiment, PriceHistory
from common.models.exchanges import ExchangeSymbol
from common.deps.config import CoreNewsSettings
settings = CoreNewsSettings()

log = logging.getLogger(__name__)
analyzer = SentimentIntensityAnalyzer()

# === NewsAPI config ===
NEWS_ENDPOINT = settings.NEWS_ENDPOINT
NEWS_PARAMS = settings.NEWS_PARAMS
BLACKLIST_SOURCES = settings.BLACKLIST_SOURCES
KEYWORD_TO_SYMBOL = settings.KEYWORD_TO_SYMBOL
DEFAULT_HALT_THRESHOLD = settings.DEFAULT_HALT_THRESHOLD
DEFAULT_LOOKBACK_HOURS = settings.DEFAULT_LOOKBACK_HOURS

def _parse_ts(ts_str: str) -> Optional[datetime]:
    if not ts_str:
        return None
    return datetime.fromisoformat(ts_str.replace("Z", "+00:00")).astimezone(timezone.utc)

async def fetch_latest_news() -> List[dict]:
    """–¢—è–≥–Ω–µ –±–∞—Ç—á —Å–≤—ñ–∂–∏—Ö –Ω–æ–≤–∏–Ω —ñ–∑ NewsAPI —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î –ø–æ–ª—è."""
    try:
        async with httpx.AsyncClient(timeout=15) as client:
            response = await client.get(
                NEWS_ENDPOINT,
                params=NEWS_PARAMS,
                headers={"X-Api-Key": settings.NEWSAPI_KEY},
            )
            response.raise_for_status()
            data = response.json()
            articles = data.get("articles", [])

        return [
            {
                "title": a.get("title", "") or "",
                "summary": a.get("description", "") or "",
                "published_at": _parse_ts(a.get("publishedAt")),
                "url": a.get("url", "") or "",
                "source": (a.get("source") or {}).get("name", "") or "",
            }
            for a in articles
            if (a.get("source") or {}).get("name", "") not in BLACKLIST_SOURCES
        ]
    except httpx.HTTPStatusError as e:
        log.error("‚ùå NewsAPI HTTP %s: %s", e.response.status_code, e.response.text[:400])
    except Exception:
        log.exception("‚ùå Error fetching news")
    return []

async def get_symbol_id(session: AsyncSession, text: str) -> Optional[uuid.UUID]:
    """–®—É–∫–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π exchange_symbols.id –∑–∞ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ —É —Ç–µ–∫—Å—Ç—ñ –Ω–æ–≤–∏–Ω–∏."""
    if not text:
        return None

    text_lower = text.lower()
    for keyword, mapped_symbol in KEYWORD_TO_SYMBOL.items():
        if keyword in text_lower and mapped_symbol:
            q = sa.select(ExchangeSymbol.id).where(ExchangeSymbol.symbol == mapped_symbol)
            res = await session.execute(q)
            symbol_id = res.scalar_one_or_none()
            if symbol_id:
                return symbol_id
    return None

async def save_news_to_db(news_items: List[dict], session: AsyncSession) -> None:
    """–ó–±–µ—Ä—ñ–≥–∞—î –Ω–æ–≤–∏–Ω–∏ —É NewsSentiment (idempotent –ø–æ published_at + title)."""
    inserted_count = 0
    for news in news_items:
        if not news.get("published_at") or not news.get("title"):
            continue

        q = select(NewsSentiment).where(
            NewsSentiment.published_at == news["published_at"],
            NewsSentiment.title == news["title"][:500],
        )
        existing = (await session.execute(q)).scalar_one_or_none()
        if existing:
            continue

        text = f"{news['title']} {news.get('summary', '')}"
        score = analyzer.polarity_scores(text)

        symbol_id = await get_symbol_id(session, news["title"])

        db_news = NewsSentiment(
            published_at=news["published_at"],
            title=news["title"][:500],
            summary=news.get("summary", "")[:1000],
            sentiment=score["compound"],
            source=news.get("source", "newsapi"),
            symbol_id=symbol_id,
            url=news.get("url", ""),
        )
        session.add(db_news)
        inserted_count += 1

    await session.commit()
    log.info("‚úÖ Inserted %s news into DB", inserted_count)

async def _get_price_at(session: AsyncSession, symbol_id: uuid.UUID, target_ts: datetime, before: bool = False) -> Optional[float]:
    """–û—Ç—Ä–∏–º–∞—Ç–∏ –Ω–∞–π–±–ª–∏–∂—á—É —Ü—ñ–Ω—É –¥–æ —á–∞—Å—É target_ts."""
    if before:
        # —Ü—ñ–Ω–∞ ‚â§ published_at (–æ—Å—Ç–∞–Ω–Ω—ñ–π –∑–∞–ø–∏—Å –ø–µ—Ä–µ–¥ –Ω–æ–≤–∏–Ω–æ—é)
        q = (
            select(PriceHistory.price)
            .where(PriceHistory.symbol_id == symbol_id, PriceHistory.timestamp <= target_ts)
            .order_by(PriceHistory.timestamp.desc())
            .limit(1)
        )
    else:
        # —Ü—ñ–Ω–∞ –Ω–∞–π–±–ª–∏–∂—á–∞ –ø—ñ—Å–ª—è target_ts
        q = (
            select(PriceHistory.price)
            .where(PriceHistory.symbol_id == symbol_id, PriceHistory.timestamp >= target_ts)
            .order_by(PriceHistory.timestamp.asc())
            .limit(1)
        )
    res = await session.execute(q)
    return res.scalar_one_or_none()

async def update_news_prices(session: AsyncSession) -> None:
    """–ü—Ä–æ—Å—Ç–∞–≤–ª—è—î —Ü—ñ–Ω–∏ –¥–æ/–ø—ñ—Å–ª—è –¥–ª—è –Ω–æ–≤–∏–Ω –æ—Å—Ç–∞–Ω–Ω—ñ—Ö 2 –¥–Ω—ñ–≤ —ñ –ø—Ä–æ—Ä–∞—Ö–æ–≤—É—î % –∑–º—ñ–Ω–∏."""
    now = dt.datetime.utcnow()

    q = select(NewsSentiment).where(NewsSentiment.published_at >= now - dt.timedelta(days=2))
    results = (await session.execute(q)).scalars().all()

    for news in results:
        if not news.symbol_id:
            continue  # –Ω–æ–≤–∏–Ω–∞ –Ω–µ –ø—Ä–∏–≤‚Äô—è–∑–∞–Ω–∞ –¥–æ —Å–∏–º–≤–æ–ª–∞

        ts = news.published_at

        # –¶—ñ–Ω–∞ –¥–æ –Ω–æ–≤–∏–Ω–∏
        price_before = await _get_price_at(session, news.symbol_id, ts, before=True)

        # –¶—ñ–Ω–∏ –ø—ñ—Å–ª—è –Ω–æ–≤–∏–Ω–∏
        price_after_1h = await _get_price_at(session, news.symbol_id, ts + dt.timedelta(hours=1))
        price_after_6h = await _get_price_at(session, news.symbol_id, ts + dt.timedelta(hours=6))
        price_after_24h = await _get_price_at(session, news.symbol_id, ts + dt.timedelta(hours=24))

        # –ó–∞–ø–∏—Å–∞—Ç–∏ –≤ –º–æ–¥–µ–ª—å
        news.price_before = price_before
        news.price_after_1h = price_after_1h
        news.price_after_6h = price_after_6h
        news.price_after_24h = price_after_24h

        if price_before and price_after_1h:
            news.price_change_1h = float((price_after_1h - price_before) / price_before * 100)
        if price_before and price_after_6h:
            news.price_change_6h = float((price_after_6h - price_before) / price_before * 100)
        if price_before and price_after_24h:
            news.price_change_24h = float((price_after_24h - price_before) / price_before * 100)

    await session.commit()
    log.info("‚úÖ Updated prices for %s news items", len(results))

# === –ê–≥—Ä–µ–≥–∞—Ü—ñ—è —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç—É —Ç–∞ HALT-–ª–æ–≥—ñ–∫–∞ ===
async def _avg_recent_sentiment(session: AsyncSession, hours: int = DEFAULT_LOOKBACK_HOURS) -> Optional[float]:
    """–°–µ—Ä–µ–¥–Ω—ñ–π compound-—Å–µ–Ω—Ç–∏–º–µ–Ω—Ç –Ω–æ–≤–∏–Ω –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ N –≥–æ–¥–∏–Ω –∑ NewsSentiment."""
    cutoff = datetime.utcnow() - timedelta(hours=hours)
    q = select(func.avg(NewsSentiment.sentiment)).where(NewsSentiment.published_at >= cutoff)
    res = await session.execute(q)
    return res.scalar_one_or_none()

async def check_news_and_halt_trading(session: AsyncSession) -> None:
    """
    –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü—ñ—è:
      1) fetch —Å–≤—ñ–∂–∏—Ö –Ω–æ–≤–∏–Ω
      2) save —É –ë–î —ñ–∑ compound-—Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–æ–º
      3) update —Ü—ñ–Ω –¥–æ/–ø—ñ—Å–ª—è
      4) aggregate sentiment (–∑–∞ –≤—ñ–∫–Ω–æ lookback) —Ç–∞, —è–∫—â–æ –Ω–∏–∂—á–µ –ø–æ—Ä–æ–≥–∞ ‚Äî HALT (–ø–æ–∫–∏ –ª–æ–≥/TODO)
    """
    # 1) fetch
    items = await fetch_latest_news()
    if not items:
        log.info("‚ÑπÔ∏è No fresh news fetched from NewsAPI")
    else:
        # 2) save
        await save_news_to_db(items, session)

    # 3) update prices (–æ–ø—Ü—ñ–π–Ω–æ; –Ω–µ –±–ª–æ–∫—É—î–º–æ —Ü–∏–∫–ª —É –≤–∏–ø–∞–¥–∫—É –ø–æ–º–∏–ª–∫–∏)
    try:
        await update_news_prices(session)
    except Exception as e:
        log.warning("‚ö†Ô∏è update_news_prices failed: %s", e)

    # 4) aggregate & decision
    lookback_h = getattr(settings, "NEWS_LOOKBACK_HOURS", None) or int(os.getenv("NEWS_LOOKBACK_HOURS", DEFAULT_LOOKBACK_HOURS))
    avg_sent = await _avg_recent_sentiment(session, hours=lookback_h)
    if avg_sent is None:
        log.info("‚ÑπÔ∏è No news in the last %s hours to aggregate sentiment", lookback_h)
        return

    threshold_cfg = getattr(settings, "HALT_TRADE_NEG_SENTIMENT", None)
    threshold = float(threshold_cfg) if threshold_cfg is not None else float(os.getenv("HALT_TRADE_NEG_SENTIMENT", DEFAULT_HALT_THRESHOLD))

    log.info("üì∞ Avg news sentiment (last %sh): %.3f; threshold: %.2f", lookback_h, avg_sent, threshold)

    if avg_sent <= threshold:
        # TODO: –†–µ–∞–ª—å–Ω–∞ —ñ–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü—ñ—è –∑—É–ø–∏–Ω–∫–∏ —Ç–æ—Ä–≥—ñ–≤–ª—ñ:
        # await set_global_trading_halt(session, reason="news_negative",
        #                               until=datetime.utcnow() + timedelta(hours=1))
        log.warning("üö® Negative average sentiment (%.3f <= %.2f) ‚Üí HALT trading (TODO: persist/notify)", avg_sent, threshold)
    else:
        log.info("‚úÖ Sentiment above threshold, trading stays enabled")


# –ü—Ä–∏–∫–ª–∞–¥ –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è –º–∞–π–±—É—Ç–Ω—å–æ–≥–æ:
# async def set_global_trading_halt(session: AsyncSession, reason: str, until: datetime) -> None:
#     """
#     –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –ø—Ä–∞–ø–æ—Ä HALT —É –≤–∞—à—ñ–π —Ç–∞–±–ª–∏—Ü—ñ –∫–æ–Ω—Ñ—ñ–≥—ñ–≤/—Ñ—ñ—á-—Ñ–ª–∞–≥—ñ–≤ –∞–±–æ –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ –ø–æ–¥—ñ—é –≤ —ñ–Ω—à–∏–π —Å–µ—Ä–≤—ñ—Å.
#     """
#     ...
